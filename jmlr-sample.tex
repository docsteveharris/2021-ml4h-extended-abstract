 % use the "wcp" class option for workshop and conference
 % proceedings
 %\documentclass[gray]{jmlr} % test grayscale version
 %\documentclass[tablecaption=bottom]{jmlr}% journal article
 \documentclass[pmlr,twocolumn,10pt]{jmlr} % W&CP article

% \usepackage{geometry}
% \geometry{margins=0.1in,textwidth=7in}

 % The following packages will be automatically loaded:
 % amsmath, amssymb, natbib, graphicx, url, algorithm2e

 %\usepackage{rotating}% for sideways figures and tables
 %\usepackage{longtable}% for long tables

 % The booktabs package is used by this sample document
 % (it provides \toprule, \midrule and \bottomrule).
 % Remove the next line if you don't require it.

\usepackage{booktabs}
 % The siunitx package is used by this sample document
 % to align numbers in a column by their decimal point.
 % Remove the next line if you don't require it.
\usepackage[load-configurations=version-1]{siunitx} % newer version 
%\usepackage{siunitx}

\usepackage{dirtytalk}

 % The following command is just for this sample document:
\newcommand{\cs}[1]{\texttt{\char`\\#1}}% remove this in your real article

% The following is to recognise equal contribution for authorship
\newcommand{\equal}[1]{{\hypersetup{linkcolor=black}\thanks{#1}}}

 % Define an unnumbered theorem just for this sample document for
 % illustrative purposes:
\theorembodyfont{\upshape}
\theoremheaderfont{\scshape}
\theorempostheader{:}
\theoremsep{\newline}
\newtheorem*{note}{Note}

 % change the arguments, as appropriate, in the following:
\jmlrvolume{LEAVE UNSET}
\jmlryear{2021}
\jmlrsubmitted{LEAVE UNSET}
\jmlrpublished{LEAVE UNSET}
\jmlrworkshop{Machine Learning for Health (ML4H) 2021} % W&CP title

 % The optional argument of \title is used in the header
\title[Short Title]{An integrated development and deployment platform for machine learning for health}
%  Full Title of Article\titlebreak This Title Has A Line Break

 % Anything in the title that should appear in the main title but 
 % not in the article's header or the volume's table of
 % contents should be placed inside \titletag{}

 %\title{Title of the Article\titletag{\thanks{Some footnote}}}


 % Use \Name{Author Name} to specify the name.
 % If the surname contains spaces, enclose the surname
 % in braces, e.g. \Name{John {Smith Jones}} similarly
 % if the name has a "von" part, e.g \Name{Jane {de Winter}}.
 % If the first letter in the forenames is a diacritic
 % enclose the diacritic in braces, e.g. \Name{{\'E}louise Smith}

 % \thanks must come after \Name{...} not inside the argument for
 % example \Name{John Smith}\nametag{\thanks{A note}} NOT \Name{John
 % Smith\thanks{A note}}

 % Anything in the name that should appear in the title but not in the 
 % article's header or footer or in the volume's
 % table of contents should be placed inside \nametag{}

 % Two authors with the same address
 % \author{%
 %  \Name{Author Name1\nametag{\thanks{A note}}} \Email{abc@sample.com}\and
 %  \Name{Author Name2} \Email{xyz@sample.com}\\
 %  \addr Address
 % }

 % Three or more authors with the same address:
 % \author{%
 %  \Name{Author Name1} \Email{an1@sample.com}\\
 %  \Name{Author Name2} \Email{an2@sample.com}\\
 %  \Name{Author Name3} \Email{an3@sample.com}\\
 %  \Name{Author Name4} \Email{an4@sample.com}\\
 %  \Name{Author Name5} \Email{an5@sample.com}\\
 %  \Name{Author Name6} \Email{an6@sample.com}\\
 %  \Name{Author Name7} \Email{an7@sample.com}\\
 %  \Name{Author Name8} \Email{an8@sample.com}\\
 %  \Name{Author Name9} \Email{an9@sample.com}\\
 %  \Name{Author Name10} \Email{an10@sample.com}\\
 %  \Name{Author Name11} \Email{an11@sample.com}\\
 %  \Name{Author Name12} \Email{an12@sample.com}\\
 %  \Name{Author Name13} \Email{an13@sample.com}\\
 %  \Name{Author Name14} \Email{an14@sample.com}\\
 %  \addr Address
 % }

 % Authors with different addresses and equal first authors:
\author{%
\Name{Steve Harris}\equal{These authors contributed equally} \Email{s.harris8@nhs.net}\\
%\addr University X, Country 1
% footnotemark[1] is to refer to the \equal footnote
\Name{Tim Bonnici}\footnotemark[1] \Email{t.bonnici@nhs.net}\\
\Name{Tom Keen}\footnotemark[1] \Email{t.keen@ucl.ac.uk}\\
\addr Institute of Health Informatics, University College London, UK
\AND
\Name{Roma Klapaukh} \Email{r.klapaukh@ucl.ac.uk}\\
\Name{Sarah Keating} \Email{s.keating@ucl.ac.uk}\\
\Name{Stef Piatek} \Email{s.piatek@ucl.ac.uk}\\
\Name{Nel Swanepoel} \Email{c.swanepoel@ucl.ac.uk}\\
\Name{Jonathan Cooper} \Email{j.p.cooper@ucl.ac.uk}\\
\addr Centre for Advanced Research Computing, University College London, UK
\AND
\Name{Aasiyah Rashan} \Email{aasiyah.rashan@nhs.net}\\
\Name{David Brealey} \Email{d.brealey@nhs.net}\\
\Name{Niall MacCallum} \Email{n.maccallum@nhs.net}\\
\Name{Mark White} \Email{mark.white4@nhs.net}\\
\addr University College London Hospital, UK
}

\begin{document}

\maketitle

\begin{abstract}
This is the abstract for this article.
\end{abstract}
\begin{keywords}
Electronic Health Records, Translational Medicine, Software Engineering
\end{keywords}

\section{Introduction}
\label{sec:intro}

Machine learning for Health (ML4H) has been expected to impact patient outcomes through diagnostic insights, personalised treatment recommendations, and organisational optimisation.\citep{yu2018, topol2019a} Yet there are only a handful of examples of algorithms crossing the \say{AI chasm}: \say{the gulf between developing a scientifically sound algorithm and its use in any meaningful real-world applications.}\citep{keane2018a}\\
This \textit{code to bedside} journey is classically separated into development and deployment stages.\\
\subsection{Development versus Deployment}
\subsubsection{Development}
The development process is \textit{offline}. An algorithm is developed against a static data extract from the reporting database downstream from the live Electronic Health Record (EHR). Code is written to  'tidy' the data, to generate labels and features, and to split the extract into train/test/validate subsets. An iterative process then ensues as different modelling approaches are investigated, the labels are refined, and features are updated, added or removed. Eventually, the final best model will be chosen for academic publication.\\
\subsubsection{Deployment}
The deployment process is \textit{online}. The algorithm must be instantiated against live data for clinical evaluation but the reporting database and the live record are typically modelled differently. The Extract-Transform-Load (ETL) process that generated the original static data extract comes from the reporting database that is built nightly and can rarely be made 'live'. This latency is unable to support inpatient clinical or operational decision making. Instead custom data feeds must be prepared directly from the EHR for each feature of the algorithm.\citep{sendak2020} Fast Healthcare Interoperability Resources (FHIR) Application Programming Interfaces (API) may help but are rarely comprehensive.[fhir-adoption] More importantly the technical skills required for deployment (web programming interfaces, application development) differ from those for development (data extraction [SQL], data wrangling and model building [Python, R etc.]). Often the deployment step requires a different team.\\
Separate development and deployment domains mean that only the best algorithms can justify the expense of recreating the pipeline for deployment. But without deployment, it is not possible to evaluate the safety and efficacy an algorithm. Excellent performance on retrospective data does not mean that the predictions will be impactful or effective.\citep{the2021} \textit{Code to bedside} testing is needed to identify how predictive insights can be used by the clinical team to improve care.

% This is a sample article that uses the \textsf{jmlr} class with
% the \texttt{wcp} class option.  Please follow the guidelines in
% this sample document as it can help to reduce complications when
% combining the articles into a book. Please avoid using obsolete
% commands, such as \verb|\rm|, and obsolete packages, such as
% \textsf{epsfig}.\footnote{See
% \url{http://www.ctan.org/pkg/l2tabu}} Some packages that are known
% to cause problems for the production editing process are checked for
% by the \textsf{jmlr} class and will generate an error. (If you want
% to know more about the production editing process, have a look at
% the video tutorials for the production editors at
% \url{http://www.dickimaw-books.com/software/makejmlrbookgui/videos/}.)

% Please also ensure that your document will compile with PDF\LaTeX.
% If you have an error message that's puzzling you, first check for it
% at the UK TUG FAQ
% \url{https://texfaq.org/FAQ-man-latex}.  If
% that doesn't help, create a minimal working example (see
% \url{https://www.dickimaw-books.com/latex/minexample/}) and post
% to somewhere like \TeX\ on StackExchange
% (\url{http://tex.stackexchange.com/}) or the \LaTeX\ Community Forum
% (\url{http://www.latex-community.org/forum/}).

% \begin{note}
% This is an numbered theorem-like environment that was defined in
% this document's preamble.
% \end{note}

\subsection{Problem statement}
We argue that the structural separation of the offline and online stages creates enormous inefficiencies.\citep{vaitla2020a} This is akin to the classical 'bench to bedside' drug development pipeline where only a handful of molecules graduate from the thousands of candidates evaluated. For drugs, the pre-clinical (offline) stage is laboratory based, and distinct from the clinical (development) phase 1-3 drug trials. Cost increases moving through the pipeline, and the commercial return must be justified by efficacy and the potential market. Very few drugs will justify the investment to seek FDA or MHRA approval. 

\begin{figure}[htbp]
 % Caption and label go in the first argument and the figure contents
 % go in the second argument
\floatconts
  {fig:nodes}
  {\caption{Drug discovery}}
  {\includegraphics[width=1.0\linewidth]{images/pipeline-drugs.png}}
\end{figure}

\begin{figure}[htbp]
 % Caption and label go in the first argument and the figure contents
 % go in the second argument
\floatconts
  {fig:nodes}
  {\caption{Algorithm discovery}}
  {\includegraphics[width=1.0\linewidth]{images/pipeline-algorithms.png}}
\end{figure}


![](../figs/pipeline-drugs.png)
![](../figs/pipeline-algorithms.png)
Improving the efficiency of this pathway is a key concern of traditional translational medicine[@ref for translational medicine], but is not yet an area of focus for digital translational medicine.

\section{Methods}
We report here the Experimental Medicine Application Platform (EMAP) that unifies the data and the tools for off-line and online development of ML4H models. In brief, EMAP builds a patient orientated SQL database from HL7 version 2 (HL7v2) messages that are being exchanged between hospital systems. HL7v2 messages are ubiquitous in health care, and the de facto standard for internal communication.

\subsection{Design principles}
We adopted the following design principles.

\subsubsection{Protection of operational systems}
The EHR is a care tool as well as record, and clinical service must be prioritised above development work. Traditionally this means that EHR teams are rightly cautious of applications that are deployed against the live record. Yet the same technical and administrative controls that defend the system are not compatible with an iterative and agile approach to development and deployment.
EMAP is implemented as a shadow data store built from the ephemeral HL7 messages that are already used for communication between hospital systems. A single copy of each message is captured just once as it passes through the hospital integration engine adding only a minimal burden on the live system. Subsequent development is downstream of the EHR which is protected from malformed queries or other problems.

\subsubsection{Live data}
The data must be available at the appropriate cadence for clinical and operational decision making. That is as long as a clinic or bedside consultation lasts (seconds to minutes). This is slower than medical devices generating near instant alarms, but an order of magnitude faster than business intelligence (the core purpose of reporting warehouses).
Live data brings an orthogonal but important secondary benefit in that it inverts the \textit{data to code} paradigm.\citep{guinney2018} Integrating development and deployment mandates a platform within the same security envelope as the EHR. This \textit{code to data} approach avoids many of the well known challenges of data sharing that troubles health data research.\citep{powles2017} Instead, developers come to work with data under the same controls and protections as the original record.

\subsubsection{SQL as an API: \textit{Boring is good}}
We wish to align the skills for development and deployment processes, and chose to use a relational database as the medium for data access and exchange. Development teams already use Structured Query Language (SQL) in their offline work. FHIR would be an attractive alternative but is not fit for bulk queries, nor able to handle procedures such as joins or aggregation.[@ref:SQL on FHIR] Flat (bulk) FHIR is not mature, nor designed for live interactions.[@ref: Epic documentation; FHIR team] We use the term 'SQL as an API' to reflect the division of responsibility. The ML4H team are protected from dealing with the local EHR implementation and HL7v2 adaptions, but have access to training and live data in the same model using familiar tools.

\subsubsection{Community building}
We used HL7v2 messages as our primary means of access to the EHR because this would allow EMAP to be used in other hospitals. We acknowledge that the flexibility of the HL7v2 specification (unlike FHIR) means that the interfaces would need adapting. This cost is offset by the widespread availability of existing HL7 feeds for key domains such as Admission/Discharge/Transfer (ADT), laboratory orders and results, and prescriptions. We also found it cost effective to implement new HL7 interfaces for notes, measurements and observations (e.g. vital signs).

\subsection{Implementation}
The EMAP data pipeline consists of the following components.

\begin{figure}[htbp]
 % Caption and label go in the first argument and the figure contents
 % go in the second argument
\floatconts
  {fig:nodes}
  {\caption{Experimental Medicine Application Platform}}
  {\includegraphics[width=1.0\linewidth]{images/emap-summary-Page-1.png}}
\end{figure}

\begin{enumerate}
    \item An additional interface is connected to the hospital HL7 integration engine that consumes a subset of all messages.
    \item These messages are copied to a PostgreSQL database called the Immutable Data Store (IDS). Each raw message is stored with a unique message identifier and a small amount of metadata (e.g. message source, message type, message timestamp). With the IDS, it becomes possible to replay messages from any point in time, and therefore rebuild at will any downstream structures.
    \item The \textbf{message-reader} processes the live messages as they appear in the IDS. It converts each message to an in-house interchange format that is coded as a Java package involving a set of serialisable Java classes, serialised test messages for integration and system testing and helper methods for testing. The format has been designed to formalise custom HL7 implementation semantics into use-specific fields, allowing the processing of these messages downstream to be ignorant of HL7. 
    \item Separately, a \textbf{table-reader} performs the same job as the message-reader but working from one or more databases rather than the message store. This permits access to historical data that was shared prior to the 'go-live' date of any particular feed. It also allows ingestion of data that is not yet being shared through the integration engine. Both the message-reader and the table-reader convert to the same interchange format.
    \item Messages, in the interchange format, are batched and sent to an appropriate queue managed by a RabbitMQ server. Priority is given to messages originating with the live stream. Each queue has a maximum number of messages that are allowed, and the services publishing to the queues implement an exponential backoff policy to limit the amount of disk space used by the queues.
    \item A \textbf{event-processor} receives and processes messages from the RabbitMQ server. Processing involves managing a set of identifiers that allows each data item from the message to be linked to a patient (via a medical record number [MRN]) and the healthcare encounter. Specific issues that are managed by the event-processor include:
    \begin{enumerate}
        \item \textit{Inferring context}: HL7 messages are normally sent with a single purpose: to notify an admission, or discharge, request a laboratory test or update a result. However, each message contains segments of contextual information including demographics, and context about that hospital encounter. This means that we can infer that a patient was admitted from a discharge message, or a test was ordered from a result message, and so on. We use this 'by stander' information to construct as complete a view of the current and ongoing state of the hospital as possible.
        \item \textit{Messages arriving out of order}: Messages will sometimes arrive out of order. For example, a discharge before an admission. The **event-processor** infers context where necessary to make sense of these situations, and then corrects and updates when prior information is made available at a later time.
        \item \textit{Patients having more than one MRN}: Patients may inadvertently re-register with the hospital because sufficient information is not available to match to an existing record or because erroneous information blocks a match. The records will eventually be flagged for a merge, and the **event-processor** will both update the stored identifiers and maintain an audit record of the change.
    \end{enumerate}
\end{enumerate}

\section{Case Study}
Early identification of patients attending the Emergency Department (ED) who would require admission to a hospital bed could improve operational efficiency. We built models to predict a 'decision to admit' at the moment of arrival to the ED, and updated the predictions as further clinical information became available. These individual predictions were aggregated to create an estimate of the total bed demand. Live estimates of total demand were used to make decisions about elective surgical work, and to pro-actively accelerate planned discharges. 
A secondary objective was to improve performance against the national target of admission within 4 hours from ED.\citep{kings2021} \\
Important features for the arrival model included age, mode of arrival (ambulance versus walking), recent hospitalisation, initial ED location (resuscitation, majors or minors), and vital signs at triage. Subsequent models included information on laboratory orders, then results, treatments and updated vital signs. Individual predictions were generated from random forest and gradient boosting classifiers. The AUC in the validation data increased from 0.85 on arrival to 0.88 after 2 hours (as clinical information was added), and then fell to 0.83 at 6 hours as class imbalance decreased and the population at risk changed.\\
We transitioned these models from offline to live, and started an iterative process with the end users (ED clinicians and the bed management team) who guided model development and deployment into their workflow. Clinician advice improved feature engineering for acute physiology by adopting classification boundaries from severity of illness scores. We responded to requests for interpretable outputs but generating displays of feature weights for individual predictions. And we organised model runs (at 6am, 12pm, 4pm, and 10pm) around the daily workflow of the bed management team.\\
All updates and modifications were done by the development team, and would not have been possible without a live deployment to stimulate feedback.  

\section{Discussion}

TODO


The bibliography is displayed using \verb|\bibliography|.

\acks{Acknowledgements go here.}

\bibliography{jmlr-sample}

\appendix

\section{First Appendix}\label{apd:first}

Appendices aren't included in the 4 page limit\\
Neither are references\\
But they warn that the appendix might not be read by the judges\\

TODO: Could place larger versions of the figures here
TODO: Could move some of the detail of the pipeline here

\section{Second Appendix}\label{apd:second}

This is the second appendix.

\end{document}
